{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in /home/ali/anaconda3/lib/python3.11/site-packages (0.10.0)\n",
      "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /home/ali/anaconda3/lib/python3.11/site-packages (from hazm) (0.9.2)\n",
      "Requirement already satisfied: flashtext<3.0,>=2.7 in /home/ali/anaconda3/lib/python3.11/site-packages (from hazm) (2.7)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /home/ali/anaconda3/lib/python3.11/site-packages (from hazm) (4.3.2)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/ali/anaconda3/lib/python3.11/site-packages (from hazm) (3.8.1)\n",
      "Requirement already satisfied: numpy==1.24.3 in /home/ali/anaconda3/lib/python3.11/site-packages (from hazm) (1.24.3)\n",
      "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /home/ali/anaconda3/lib/python3.11/site-packages (from hazm) (0.9.10)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /home/ali/anaconda3/lib/python3.11/site-packages (from hazm) (1.2.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/ali/anaconda3/lib/python3.11/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.11.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/ali/anaconda3/lib/python3.11/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (68.2.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/ali/anaconda3/lib/python3.11/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ali/anaconda3/lib/python3.11/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (5.2.1)\n",
      "Requirement already satisfied: click in /home/ali/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ali/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ali/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /home/ali/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.65.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ali/anaconda3/lib/python3.11/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (2.2.0)\n",
      "Requirement already satisfied: pandas in /home/ali/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /home/ali/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ali/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ali/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ali/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ali/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('./crawler/news_newformat_745.json')\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Displaying Some Sample Records of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>category</th>\n",
       "      <th>datetime</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3063320</th>\n",
       "      <td>افشای تصاویر مهاجمین مسلح حمله تروریستی مسکو</td>\n",
       "      <td>تصاویر ۵ نفر از مهاجمین مسلح حمله تروریستی مسک...</td>\n",
       "      <td>رسانه‌ها، تصویر ۵ نفر از دستکم ۱۰ مهاجم عملیلت...</td>\n",
       "      <td>[عملیات تروریستی, جنگ اوکراین]</td>\n",
       "      <td>[سیاسی, بین الملل]</td>\n",
       "      <td>2024-03-22T20:57:48Z</td>\n",
       "      <td>https://www.khabarfoori.com/بخش-%D8%B3%DB%8C%D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063319</th>\n",
       "      <td>مرگ تلخ ۳ عضو یک خانواده در تصادف رانندگی/ کود...</td>\n",
       "      <td>مدیر شبکه بهداشت و درمان پارس آباد از مرگ تلخ ...</td>\n",
       "      <td>دکتر منصور مهمان نواز  با بیان اینکه تمامی  فو...</td>\n",
       "      <td>[پارس آباد, تصادف جاده ای, تصادف رانندگی, کشته...</td>\n",
       "      <td>[حوادث, تصادف]</td>\n",
       "      <td>2024-03-22T20:13:30Z</td>\n",
       "      <td>https://www.khabarfoori.com/بخش-%D8%AD%D9%88%D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063318</th>\n",
       "      <td>ایران حمله تروریستی در روسیه را محکوم کرد</td>\n",
       "      <td>سخنگوی وزارت امور خارجه کشورمان حمله تروریستی ...</td>\n",
       "      <td>ناصر کنعانی ضمن ابراز تسلیت به دولت و ملت روسی...</td>\n",
       "      <td>[روسیه, سخنگوی وزارت امور خارجه, حادثه تروریستی]</td>\n",
       "      <td>[سیاسی, سیاست خارجی]</td>\n",
       "      <td>2024-03-22T20:07:36Z</td>\n",
       "      <td>https://www.khabarfoori.com/بخش-%D8%B3%DB%8C%D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063317</th>\n",
       "      <td>پای چه‌کسانی در \"فاجعه کروکوس\" در میان است؟ / ...</td>\n",
       "      <td>عملیات تروریستی در مسکو تنها ساعاتی پس از آن ر...</td>\n",
       "      <td>جالب اینکه ۱۸ اسفند ماه سفارت آمریکا در روسیه ...</td>\n",
       "      <td>[عملیات تروریستی, جنگ اوکراین]</td>\n",
       "      <td>[سیاسی, بین الملل]</td>\n",
       "      <td>2024-03-22T20:07:11Z</td>\n",
       "      <td>https://www.khabarfoori.com/بخش-%D8%B3%DB%8C%D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063316</th>\n",
       "      <td>رعنا آزادی ور عزادار شد</td>\n",
       "      <td>رعنا آزادی ور، بازیگر سینما و تلویزیون، چند سا...</td>\n",
       "      <td>رعنا آزادی ور  متولد فروردین ماه سال 1362 می ب...</td>\n",
       "      <td>[سوگ پدر, رعنا آزادی ور]</td>\n",
       "      <td>[فرهنگی, چهره ها]</td>\n",
       "      <td>2024-03-22T20:04:14Z</td>\n",
       "      <td>https://www.khabarfoori.com/بخش-%D9%81%D8%B1%D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "3063320       افشای تصاویر مهاجمین مسلح حمله تروریستی مسکو   \n",
       "3063319  مرگ تلخ ۳ عضو یک خانواده در تصادف رانندگی/ کود...   \n",
       "3063318          ایران حمله تروریستی در روسیه را محکوم کرد   \n",
       "3063317  پای چه‌کسانی در \"فاجعه کروکوس\" در میان است؟ / ...   \n",
       "3063316                            رعنا آزادی ور عزادار شد   \n",
       "\n",
       "                                                      lead  \\\n",
       "3063320  تصاویر ۵ نفر از مهاجمین مسلح حمله تروریستی مسک...   \n",
       "3063319  مدیر شبکه بهداشت و درمان پارس آباد از مرگ تلخ ...   \n",
       "3063318  سخنگوی وزارت امور خارجه کشورمان حمله تروریستی ...   \n",
       "3063317  عملیات تروریستی در مسکو تنها ساعاتی پس از آن ر...   \n",
       "3063316  رعنا آزادی ور، بازیگر سینما و تلویزیون، چند سا...   \n",
       "\n",
       "                                                      text  \\\n",
       "3063320  رسانه‌ها، تصویر ۵ نفر از دستکم ۱۰ مهاجم عملیلت...   \n",
       "3063319  دکتر منصور مهمان نواز  با بیان اینکه تمامی  فو...   \n",
       "3063318  ناصر کنعانی ضمن ابراز تسلیت به دولت و ملت روسی...   \n",
       "3063317  جالب اینکه ۱۸ اسفند ماه سفارت آمریکا در روسیه ...   \n",
       "3063316  رعنا آزادی ور  متولد فروردین ماه سال 1362 می ب...   \n",
       "\n",
       "                                                      tags  \\\n",
       "3063320                     [عملیات تروریستی, جنگ اوکراین]   \n",
       "3063319  [پارس آباد, تصادف جاده ای, تصادف رانندگی, کشته...   \n",
       "3063318   [روسیه, سخنگوی وزارت امور خارجه, حادثه تروریستی]   \n",
       "3063317                     [عملیات تروریستی, جنگ اوکراین]   \n",
       "3063316                           [سوگ پدر, رعنا آزادی ور]   \n",
       "\n",
       "                     category              datetime  \\\n",
       "3063320    [سیاسی, بین الملل]  2024-03-22T20:57:48Z   \n",
       "3063319        [حوادث, تصادف]  2024-03-22T20:13:30Z   \n",
       "3063318  [سیاسی, سیاست خارجی]  2024-03-22T20:07:36Z   \n",
       "3063317    [سیاسی, بین الملل]  2024-03-22T20:07:11Z   \n",
       "3063316     [فرهنگی, چهره ها]  2024-03-22T20:04:14Z   \n",
       "\n",
       "                                                       url  \n",
       "3063320  https://www.khabarfoori.com/بخش-%D8%B3%DB%8C%D...  \n",
       "3063319  https://www.khabarfoori.com/بخش-%D8%AD%D9%88%D...  \n",
       "3063318  https://www.khabarfoori.com/بخش-%D8%B3%DB%8C%D...  \n",
       "3063317  https://www.khabarfoori.com/بخش-%D8%B3%DB%8C%D...  \n",
       "3063316  https://www.khabarfoori.com/بخش-%D9%81%D8%B1%D...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 744 records.\n"
     ]
    }
   ],
   "source": [
    "display(df.head())\n",
    "print(f'The dataset contains {len(df)} records.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Number of Data Records in Each Major Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "سیاسی        186\n",
       "اقتصادی      142\n",
       "ورزشی         88\n",
       "فرهنگی        75\n",
       "اجتماعی       66\n",
       "حوادث         47\n",
       "سرگرمی        46\n",
       "استان‌ها      42\n",
       "دانش          28\n",
       "سبک زندگی     24\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cats = df['category']\n",
    "major_cats = cats.apply(lambda x: x[0])\n",
    "display(major_cats.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Combining All Textual Data for each Data Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>textual_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3063320</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>افشای تصاویر مهاجمین مسلح حمله تروریستی مسکو ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063319</th>\n",
       "      <td>حوادث</td>\n",
       "      <td>مرگ تلخ ۳ عضو یک خانواده در تصادف رانندگی/ کود...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063318</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>ایران حمله تروریستی در روسیه را محکوم کرد سخنگ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063317</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>پای چه‌کسانی در \"فاجعه کروکوس\" در میان است؟ / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063316</th>\n",
       "      <td>فرهنگی</td>\n",
       "      <td>رعنا آزادی ور عزادار شد رعنا آزادی ور، بازیگر ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                       textual_data\n",
       "3063320    سیاسی  افشای تصاویر مهاجمین مسلح حمله تروریستی مسکو ت...\n",
       "3063319    حوادث  مرگ تلخ ۳ عضو یک خانواده در تصادف رانندگی/ کود...\n",
       "3063318    سیاسی  ایران حمله تروریستی در روسیه را محکوم کرد سخنگ...\n",
       "3063317    سیاسی  پای چه‌کسانی در \"فاجعه کروکوس\" در میان است؟ / ...\n",
       "3063316   فرهنگی  رعنا آزادی ور عزادار شد رعنا آزادی ور، بازیگر ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combining all textual data for each record in a single column\n",
    "df['textual_data'] = df.apply(lambda row: ' '.join([\n",
    "    row['title'],\n",
    "    row['lead'],\n",
    "    row['text'],\n",
    "    *row['tags']\n",
    "]), axis=1)\n",
    "\n",
    "# Dropping unnecessay columns\n",
    "df = df.drop(columns=[\n",
    "    'title',\n",
    "    'lead',\n",
    "    'text',\n",
    "    'tags',\n",
    "    'datetime',\n",
    "    'url',\n",
    "])\n",
    "\n",
    "# Retaining only the major category for each data record\n",
    "df['category'] = df['category'].apply(lambda row: row[0])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>textual_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3063320</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>افشای تصاویر مهاجمین مسلح حمله تروریستی مسکو ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063319</th>\n",
       "      <td>حوادث</td>\n",
       "      <td>مرگ تلخ ۳ عضو یک خانواده در تصادف رانندگی / کو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063318</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>ایران حمله تروریستی در روسیه را محکوم کرد سخنگ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063317</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>پای چه‌کسانی در «فاجعه کروکوس» در میان است؟ / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063316</th>\n",
       "      <td>فرهنگی</td>\n",
       "      <td>رعنا آزادی ور عزادار شد رعنا آزادی ور، بازیگر ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                       textual_data\n",
       "3063320    سیاسی  افشای تصاویر مهاجمین مسلح حمله تروریستی مسکو ت...\n",
       "3063319    حوادث  مرگ تلخ ۳ عضو یک خانواده در تصادف رانندگی / کو...\n",
       "3063318    سیاسی  ایران حمله تروریستی در روسیه را محکوم کرد سخنگ...\n",
       "3063317    سیاسی  پای چه‌کسانی در «فاجعه کروکوس» در میان است؟ / ...\n",
       "3063316   فرهنگی  رعنا آزادی ور عزادار شد رعنا آزادی ور، بازیگر ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hazm import Normalizer\n",
    "\n",
    "\n",
    "normalizer = Normalizer()\n",
    "df['textual_data'] = df['textual_data'].apply(\n",
    "    lambda row: normalizer.normalize(row))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>textual_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3063320</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[افشای, تصاویر, مهاجمین, مسلح, حمله, تروریستی,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063319</th>\n",
       "      <td>حوادث</td>\n",
       "      <td>[مرگ, تلخ, ۳, عضو, یک, خانواده, در, تصادف, ران...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063318</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[ایران, حمله, تروریستی, در, روسیه, را, محکوم, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063317</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[پای, چه‌کسانی, در, «, فاجعه, کروکوس, », در, م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063316</th>\n",
       "      <td>فرهنگی</td>\n",
       "      <td>[رعنا, آزادی, ور, عزادار, شد, رعنا, آزادی, ور,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                       textual_data\n",
       "3063320    سیاسی  [افشای, تصاویر, مهاجمین, مسلح, حمله, تروریستی,...\n",
       "3063319    حوادث  [مرگ, تلخ, ۳, عضو, یک, خانواده, در, تصادف, ران...\n",
       "3063318    سیاسی  [ایران, حمله, تروریستی, در, روسیه, را, محکوم, ...\n",
       "3063317    سیاسی  [پای, چه‌کسانی, در, «, فاجعه, کروکوس, », در, م...\n",
       "3063316   فرهنگی  [رعنا, آزادی, ور, عزادار, شد, رعنا, آزادی, ور,..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hazm import WordTokenizer\n",
    "\n",
    "\n",
    "tokenizer = WordTokenizer()\n",
    "df['textual_data'] = df['textual_data'].apply(\n",
    "    lambda row: tokenizer.tokenize(row))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Defining Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import stopwords_list\n",
    "\n",
    "punctuations = [\n",
    "    '.',\n",
    "    '؟',\n",
    "    '!',\n",
    "    '،',\n",
    "    ':',\n",
    "    '؛',\n",
    "    ')',\n",
    "    '(',\n",
    "    '»',\n",
    "    '«',\n",
    "    '«',\n",
    "]\n",
    "stopwords = set(stopwords_list() + punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>textual_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3063320</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[افشا, تصاویر, مهاجمین, مسلح, حمله, تروریست, م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063319</th>\n",
       "      <td>حوادث</td>\n",
       "      <td>[مرگ, تلخ, ۳, عضو, خانواده, تصادف, رانندگ, /, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063318</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[ایر, حمله, تروریست, روسیه, محکو, سخنگو, وزار,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063317</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[پا, چه‌کسان, فاجعه, کروکوس, /, ناتو, اسرائیل,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063316</th>\n",
       "      <td>فرهنگی</td>\n",
       "      <td>[رعنا, آزاد, ور, عزادار, رعنا, آزاد, ور, بازیگ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                       textual_data\n",
       "3063320    سیاسی  [افشا, تصاویر, مهاجمین, مسلح, حمله, تروریست, م...\n",
       "3063319    حوادث  [مرگ, تلخ, ۳, عضو, خانواده, تصادف, رانندگ, /, ...\n",
       "3063318    سیاسی  [ایر, حمله, تروریست, روسیه, محکو, سخنگو, وزار,...\n",
       "3063317    سیاسی  [پا, چه‌کسان, فاجعه, کروکوس, /, ناتو, اسرائیل,...\n",
       "3063316   فرهنگی  [رعنا, آزاد, ور, عزادار, رعنا, آزاد, ور, بازیگ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hazm import Stemmer\n",
    "\n",
    "\n",
    "stemmer = Stemmer()\n",
    "df['textual_data'] = df['textual_data'].apply(\n",
    "    lambda row: [stemmer.stem(token) for token in row\n",
    "                 if token not in stopwords])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>textual_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3063320</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[افشا, تصاویر, مهاجمین, مسلح, حمله, تروریست, م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063319</th>\n",
       "      <td>حوادث</td>\n",
       "      <td>[مرگ, تلخ, ۳, عضو, خانواده, تصادف, رانندگ, /, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063318</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[ایر, حمله, تروریست, روسیه, محکو, سخنگو, وزار,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063317</th>\n",
       "      <td>سیاسی</td>\n",
       "      <td>[پا, چه‌کسان, فاجعه, کروکوس, /, ناتو, اسرائیل,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063316</th>\n",
       "      <td>فرهنگی</td>\n",
       "      <td>[رعنا, آزاد, ور, عزادار, رعنا, آزاد, ور, بازیگ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                       textual_data\n",
       "3063320    سیاسی  [افشا, تصاویر, مهاجمین, مسلح, حمله, تروریست, م...\n",
       "3063319    حوادث  [مرگ, تلخ, ۳, عضو, خانواده, تصادف, رانندگ, /, ...\n",
       "3063318    سیاسی  [ایر, حمله, تروریست, روسیه, محکو, سخنگو, وزار,...\n",
       "3063317    سیاسی  [پا, چه‌کسان, فاجعه, کروکوس, /, ناتو, اسرائیل,...\n",
       "3063316   فرهنگی  [رعنا, آزاد, ور, عزادار, رعنا, آزاد, ور, بازیگ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hazm import Lemmatizer\n",
    "\n",
    "\n",
    "lemmatizer = Lemmatizer()\n",
    "df['textual_data'] = df['textual_data'].apply(\n",
    "    lambda row: [lemmatizer.lemmatize(token) for token in row\n",
    "                 if token not in stopwords])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. Couting Occurences of each Token in each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category = سیاسی\n",
      "{'کشور': 522, 'سال': 504, 'ایر': 430, 'مرد': 423, 'انتخاب': 367}\n",
      "\n",
      "Category = حوادث\n",
      "{'سال': 70, 'نوروز': 69, 'پلیس': 69, 'تصادف': 60, 'تهر': 56}\n",
      "\n",
      "Category = فرهنگی\n",
      "{'سال': 180, 'نوروز': 80, 'ایر': 70, 'سینما': 66, 'برنامه': 64}\n",
      "\n",
      "Category = دانش\n",
      "{'#هست': 50, 'سال': 50, 'کار': 49, 'استفاده': 43, 'آب': 42}\n",
      "\n",
      "Category = سرگرمی\n",
      "{'کرد#کن': 211, 'داد#ده': 210, 'کار': 204, 'امروز': 204, 'سال': 195}\n",
      "\n",
      "Category = ورزشی\n",
      "{'ت': 267, 'فوتبال': 184, 'ایر': 182, 'مل': 173, 'سال': 164}\n",
      "\n",
      "Category = اقتصادی\n",
      "{'سال': 470, 'درصد': 346, 'کار': 341, 'کارگر': 325, 'قیم': 307}\n",
      "\n",
      "Category = اجتماعی\n",
      "{'کشور': 189, 'سال': 146, '#هست': 136, 'جنوب': 103, 'گیاه': 102}\n",
      "\n",
      "Category = استان‌ها\n",
      "{'شرک': 80, 'مرد': 69, 'اس': 66, 'سال': 54, 'خوزس': 53}\n",
      "\n",
      "Category = سبک زندگی\n",
      "{'غذا': 70, 'مصرف': 69, '#هست': 61, 'مواد': 53, 'بدن': 48}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "counts = {}\n",
    "for _, row in df.iterrows():\n",
    "    cat = row['category']\n",
    "    for token in row['textual_data']:\n",
    "        cat_dict = counts.setdefault(cat, {})\n",
    "        token_cnt = cat_dict.setdefault(token, 0)\n",
    "        cat_dict[token] = token_cnt + 1\n",
    "\n",
    "for cat in counts.keys():\n",
    "    print(f'Category = {cat}')\n",
    "    tops = dict(heapq.nlargest(5, counts[cat].items(), key=itemgetter(1)))\n",
    "    tops = dict(sorted(tops.items(), key=lambda x:x[1], reverse=True))\n",
    "    print(tops, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
